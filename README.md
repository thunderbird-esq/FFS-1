# Document Processing Pipeline

## Overview

This project implements a robust, three-stage document processing pipeline designed to convert scanned PDF documents (particularly vintage computer documentation) into high-quality, structured markdown files. The pipeline uses a combination of local OCR/image extraction and powerful Azure AI services for analysis and synthesis.

The entire system is orchestrated by a single command and is designed to be idempotent, observable, and resilient.

---

## Prerequisites

### System Requirements
- **OS:** macOS Catalina 10.15.7 (Darwin 19.6.0)
- **Python:** Python 3.9.x
- **System Dependencies:** Homebrew, Tesseract, Poppler, Coreutils

### Azure Services Required
- Azure OpenAI Service with a `gpt-4o` deployment.
- Azure AI Document Intelligence service.

---

## Quick Setup & Execution

1.  **Configure Azure Credentials**
    Create a `.env` file in the project root with your Azure credentials:
    ```
    AZURE_OPENAI_ENDPOINT="[https://your-resource.openai.azure.com/](https://your-resource.openai.azure.com/)"
    AZURE_OPENAI_KEY="your-32-character-api-key"
    AZURE_OPENAI_DEPLOYMENT_NAME="gpt-4o"
    OPENAI_API_VERSION="2024-02-15-preview"
    AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT="[https://your-docintel.cognitiveservices.azure.com/](https://your-docintel.cognitiveservices.azure.com/)"
    AZURE_DOCUMENT_INTELLIGENCE_KEY="your-doc-intel-key"
    ```

2.  **Run Environment Setup**
    Execute the setup script. This will validate your system, install dependencies, and create the Python virtual environment. This script is idempotent and safe to run multiple times.
    ```bash
    ./environment_setup_helper.sh
    ```

3.  **Place PDF Files**
    Copy any PDF files you want to process into the project's root directory.

4.  **Run the Pipeline**
    Execute the master orchestration script.
    ```bash
    ./run_pipeline.sh
    ```

---

## Project Structure

-   **`/` (root):** Contains the primary executable scripts (`run_pipeline.sh`, `stage_x_processing.py`, etc.).
-   **`/agents`:** Contains the Markdown specification files that define the logic for each pipeline component.
-   **`/pipeline_logs`:** Output directory for detailed execution logs.
-   **`/preprocessed_markdown`:** Output directory for Stage 1.
-   **`/document_assets`:** Output directory for images extracted in Stage 1.
-   **`/final_markdown`:** Output directory for Stage 2.
-   **`/markitdown_output`:** Final output directory for Stage 3.
-   **`/test_data`:** Contains sample PDFs for testing, generated by `create_test_data.py`.
