# stage_2_processing.py
#
# This script performs the second stage of the document processing pipeline.
# It uses Azure OpenAI's GPT-4o model for two tasks:
# 1. Vision Analysis: Analyzes extracted images to create technical descriptions.
# 2. Text Cleanup: Refines the OCR'd Markdown text from Stage 1.
# It is designed to be robust, cost-effective, and configurable.

import os
import base64
import json
import logging
import argparse
import time
from typing import Dict, List, Optional

# Third-party imports
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI
from langchain.schema.messages import HumanMessage, SystemMessage
from tenacity import retry, stop_after_attempt, wait_exponential

# --- Load Environment Variables ---
# This allows the script to be run standalone for testing,
# while the master script will set these variables directly.
load_dotenv()

# --- Setup Logging ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# --- LLM Prompts ---
IMAGE_SYSTEM_PROMPT = """You are a world-class expert in analyzing technical documentation for vintage computers, especially the Apple II and classic Macintosh series. Your task is to analyze an image and return a structured JSON object.

The image could be one of the following:
- A screenshot of a GUI (Graphical User Interface)
- A hardware schematic or block diagram
- A code snippet as an image
- A chart or graph
- A photograph of hardware

Your response MUST be a single JSON object with the following schema:
{
  "category": "string (one of: 'Screenshot', 'Diagram', 'Code Snippet', 'Chart', 'Photograph', 'Other')",
  "title": "string (A concise, one-line summary of the image's content.)",
  "description": "string (A detailed, multi-sentence paragraph describing the key elements, relationships, and purpose of the image. Be precise and technical.)"
}"""

TEXT_CLEANUP_SYSTEM_PROMPT = """You are an expert technical editor specializing in classic Apple computer documentation. Your task is to take a chunk of Markdown text generated by OCR and clean it for publication.

- Correct obvious OCR errors (e.g., '1' for 'l', 'O' for '0', mis-joined words).
- Ensure code blocks are correctly formatted with ```assembly, ```c, or ```pascal where appropriate.
- Fix any broken Markdown table syntax.
- Remove any lingering page numbers or headers that are mixed in with the content.
- Maintain the original document structure (headings, lists, etc.) perfectly.
- DO NOT add any new content, commentary, or explanations.
- Only output the cleaned, raw Markdown text."""

# --- Core Functions ---

def initialize_llm() -> Optional[AzureChatOpenAI]:
    """
    Initializes and validates the AzureChatOpenAI client from environment variables.
    """
    required_vars = [
        "AZURE_OPENAI_ENDPOINT", "AZURE_OPENAI_KEY",
        "AZURE_OPENAI_DEPLOYMENT_NAME", "OPENAI_API_VERSION"
    ]
    if not all(os.getenv(var) for var in required_vars):
        logging.error("One or more required Azure environment variables are not set.")
        logging.error(f"Required: {', '.join(required_vars)}")
        return None
    try:
        return AzureChatOpenAI(
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("AZURE_OPENAI_KEY"),
            deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
            api_version=os.getenv("OPENAI_API_VERSION"),
            temperature=0.0,
            max_retries=3,
        )
    except Exception as e:
        logging.error(f"Failed to initialize AzureChatOpenAI client: {e}")
        return None

def encode_image_to_base64(image_path: str) -> Optional[str]:
    """Encodes an image file to a base64 string."""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        logging.error(f"Failed to encode image {image_path}: {e}")
        return None

@retry(wait=wait_exponential(multiplier=2, min=5, max=60), stop=stop_after_attempt(3))
def analyze_single_image(llm: AzureChatOpenAI, image_path: str) -> Optional[Dict]:
    """
    Analyzes a single image using the LLM, with retry logic.

    Returns:
        A dictionary with the analysis results or None if it fails.
    """
    logging.info(f"  -> Analyzing image: {os.path.basename(image_path)}")
    base64_image = encode_image_to_base64(image_path)
    if not base64_image:
        return None

    human_message = HumanMessage(content=[
        {"type": "text", "text": "Please analyze this image based on the system prompt."},
        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_image}"}}
    ])
    system_message = SystemMessage(content=IMAGE_SYSTEM_PROMPT)
    
    response = llm.invoke([system_message, human_message])
    
    try:
        return json.loads(response.content)
    except (json.JSONDecodeError, TypeError) as e:
        logging.error(f"Failed to parse JSON response for {os.path.basename(image_path)}: {e}")
        logging.error(f"Raw response: {response.content}")
        return None

@retry(wait=wait_exponential(multiplier=2, min=5, max=60), stop=stop_after_attempt(3))
def cleanup_text_chunk(llm: AzureChatOpenAI, text_chunk: str) -> str:
    """Cleans a single chunk of Markdown text using the LLM, with retry logic."""
    if not text_chunk.strip():
        return ""
        
    messages = [
        SystemMessage(content=TEXT_CLEANUP_SYSTEM_PROMPT),
        HumanMessage(content=text_chunk)
    ]
    response = llm.invoke(messages)
    return response.content

def process_single_document(llm: AzureChatOpenAI, md_path: str, asset_dir: str, output_dir: str):
    """Orchestrates the full Stage 2 processing for a single document."""
    base_filename = os.path.splitext(os.path.basename(md_path))[0]
    final_md_path = os.path.join(output_dir, f"{base_filename}.md")

    if os.path.exists(final_md_path):
        logging.info(f"Skipping '{base_filename}', final version already exists.")
        return

    logging.info(f"--- Processing document: {base_filename} ---")

    # 1. Analyze Images
    manifest_path = os.path.join(asset_dir, "_manifest.json")
    image_manifest = {}
    if os.path.exists(manifest_path):
        with open(manifest_path, "r", encoding="utf-8") as f:
            image_manifest = json.load(f)

    if os.path.isdir(asset_dir):
        for image_file in sorted(os.listdir(asset_dir)):
            if image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')) and image_file not in image_manifest:
                image_path = os.path.join(asset_dir, image_file)
                analysis = analyze_single_image(llm, image_path)
                if analysis:
                    image_manifest[image_file] = analysis
                time.sleep(1) # Simple rate limiting

        with open(manifest_path, "w", encoding="utf-8") as f:
            json.dump(image_manifest, f, indent=2)
        logging.info(f"Image manifest updated at '{manifest_path}'")

    # 2. Append image analysis to original Markdown
    with open(md_path, "r", encoding="utf-8") as f:
        original_md_content = f.read()
    
    analysis_section = "\n\n## Extracted Image Analysis\n\n"
    if image_manifest:
        for filename, analysis in image_manifest.items():
            analysis_section += f"### Image: `{filename}`\n\n"
            analysis_section += f"**Category:** {analysis.get('category', 'N/A')}\n\n"
            analysis_section += f"**Title:** {analysis.get('title', 'N/A')}\n\n"
            analysis_section += f"> {analysis.get('description', 'No description available.')}\n\n---\n\n"
    else:
        analysis_section += "> No images were extracted or analyzed for this document.\n"
        
    content_to_clean = original_md_content + analysis_section

    # 3. Cleanup combined text in chunks
    logging.info("Cleaning up document text...")
    chunks = content_to_clean.split("\n## ")
    cleaned_chunks = []

    # Process first chunk (before the first "## ")
    if chunks:
        logging.info(f"  -> Cleaning chunk 1 of {len(chunks)}")
        cleaned_chunks.append(cleanup_text_chunk(llm, chunks[0]))
    
    # Process remaining chunks
    for i, chunk in enumerate(chunks[1:], start=1):
        logging.info(f"  -> Cleaning chunk {i + 1} of {len(chunks)}")
        # Re-add the chapter heading that was removed by split()
        full_chunk = "## " + chunk
        cleaned_chunks.append(cleanup_text_chunk(llm, full_chunk))
        time.sleep(1) # Simple rate limiting

    final_content = "\n\n".join(cleaned_chunks)
    
    # 4. Save final output
    with open(final_md_path, "w", encoding="utf-8") as f:
        f.write(final_content)
    logging.info(f"Successfully saved final version to '{final_md_path}'")

def main(args):
    """Main function to find and process markdown files."""
    llm = initialize_llm()
    if not llm:
        logging.error("Halting pipeline due to LLM initialization failure.")
        return

    os.makedirs(args.output_dir, exist_ok=True)
    
    md_files = [f for f in os.listdir(args.source_md_dir) if f.lower().endswith(".md")]
    logging.info(f"Found {len(md_files)} Markdown document(s) for Stage 2 processing.")
    
    for md_filename in md_files:
        try:
            md_path = os.path.join(args.source_md_dir, md_filename)
            base_name = os.path.splitext(md_filename)[0]
            doc_asset_dir = os.path.join(args.asset_dir, base_name)
            process_single_document(llm, md_path, doc_asset_dir, args.output_dir)
        except Exception as e:
            logging.error(f"FATAL ERROR on document {md_filename}: {e}", exc_info=True)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Stage 2: LLM Vision Analysis and Text Cleanup.")
    parser.add_argument("--source-md-dir", required=True, help="Directory containing markdown files from Stage 1.")
    parser.add_argument("--asset-dir", required=True, help="Root directory containing extracted image assets.")
    parser.add_argument("--output-dir", required=True, help="Directory to save the final, cleaned markdown files.")
    
    args = parser.parse_args()
    main(args)


